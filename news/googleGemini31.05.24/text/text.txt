Компания Google опубликовала разъяснения по поводу того, почему нейросеть Gemini начала предлагать пользователям странные, а иной раз вредные ответы на их вопросы, например, об использовании клея для пиццы и поедания камней.

В своём блоге корпорация утверждает, что функция нейропоиска AI Overview не выдумает что‑то самостоятельно и не «галлюцинирует». По словам представителей Google, Gemini попросту «неверно» интерпретирует нюансы языка в интернете», при этом не имея доступа к полезной информации.

Google пишет, что AI Overview основана на настраиваемой языковой модели. Эта модель интегрирована с основными системами веб‑рейтинга в поисковой системе и предназначена для выполнения традиционных задач — например, выявления релевантных результатов по индексу Google. Таким образом, Gemini начала считать советы склеивать пиццу и пить мочу наиболее подходящими результатами поиска.

В компании отмечают, что другие функции поиска, основанные на нейросетях, тоже имеют подобные проблемы, и AI Overview имеет схожую с ними точность.

Отдельно Google обвинила пользователей в том, что они подделывали результаты выдачи ответов от Gemini. В частности, в компании утверждают, что распространяемые в сети скриншоты ответов, в которых нейросеть советует оставлять собак в машинах и курить во время беременности, на самом деле не соответствуют действительности. При этом Google признаёт, что некоторые ответы AI Overview были абсурдными и бесполезными, поскольку информация для них была взята с пародийных и саркастических форумов, и нейросеть не смогла распознать троллинг.

В компании говорят, что внесли изменения в систему и выявили ошибки. Google утверждает, что обновила свои системы, чтобы ограничить в своих ответах использование контента с форумов, который может ввести пользователей в заблуждение. Кроме того, компания разработала механизм, который должен уметь распознавать сатиру и иронию, а также выявлять «бессмысленные запросы, которые не должны быть показаны».

Ранее пользователи AI Overview начали сообщать о безумных ответах на поисковые запросы, в которых им советовали прыгать с моста «Золотые ворота» для борьбы с депрессией, глотать камни для решения проблем с пищеварением, использовать клей (нетоксичный, чтобы не навредить здоровью) при приготовлении пиццы и др. Вероятно, нейросеть определяла некоторые шутливые ответы с Reddit и других форумов как популярные, что привело к выдаче вредных советов.